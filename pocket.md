## 口袋算法
### 模型介绍
1. 解决问题
   感知器学习算法的数据集是可分的，所以每次迭代的误分类数最终收敛到0。如果数据集不可分，会遇到问题，
   更新功能永不停止
   最终输出并不能保证样本内误差是最优的，
   **需要对算法修改**。
   
2. 介绍 口袋算法（Pocket Algorithm）是一个二元分类算法，将一个数据集通过线性组合的方式分成两种类型。这个算法将迄今为止看到的最好结果保存在它的口袋里（这就是它被称为口袋学习算法的原因）。最好的结果意味着错误分类的数量最少。如果新权重产生的错误分类数量少于口袋中的权重，则将口袋中的权重替换为新权重；如果新的砝码不比口袋里的好，把那个放在口袋里并丢弃新的砝码。在训练迭代结束时，算法返回口袋中的解，而不是最后的解。
### 学习步骤
  1. 将口袋权重向量化，初始化 W pocket为0或小的随机数 并将此权重向量用作感知器学习算法的初始化权重向量
  2. 对每次训练迭代，执行以下步骤
     1. 运行感知器训练步骤获得新的权重向量
     2. 通过将整个样本集上的误分类数与 执行的误分类数进行比较来进行评估
     3. 如果W(t)好于W(pocket) ，则更换W(pocket)为W(t)
  3. W(t)当训练迭代终止时返回
### 代码实现
   **应用于日本信用筛选数据集**
   此示例演示如何使用日本信用筛选数据集来训练口袋算法，预测申请人是否会被批准。
   共有 125 个样本和两个类别，正面和负面，分别是获得和未获得信用的人。每个样本有 15 个特征；在某些示例中可能会遗漏某些功能。此外，特征类型包括分类、实数和整数类型。

### 改进优化
   核口袋算法
   **基于核函数的非线性口袋算法**
   文献[ 基于核函数的非线性口袋算法 ]利用口袋算法[P roc ofthe Eighth Int Conf on Pattern Recognition] 的思想改造核感知器算法, 提出了基于核函数的非线性口袋算法(即核口袋算法) , 其目标是找到一组系数使错分样本数为最少. 对于核口袋算法, 其收敛性可以借助于口袋算法的收敛性[ On Convergence Properties of PocketA lgorithm ] 来证明. 为了进一步改善核口袋算法的推广能力, 文献[ LargeMargin Kernel PocketA lgorithm] 引入支持向量机算法中最大化两类之间间隔的思想, 定义了反映两类样本之间距离大小的准则: 间隔准则. 在核口袋算法的迭代过程中最大化这一准则, 使迭代过程同时最小化错分样本数和最大化间隔准则, 称之为大间隔核口袋算法. 

